{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = pd.read_csv('data/positive.csv', sep = ';', header = None)\n",
    "negative_tweets = pd.read_csv('data/negative.csv', sep = ';', header = None)\n",
    "dataset = pd.concat([positive_tweets, negative_tweets])[[3, 4]]\n",
    "dataset.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мыс на меня обиделась:(\\nя ей даже ничего не с...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аааааааааааааааааааа,не хочу на работу :(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У меня какой-то особенный вид ушей! :D, некото...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@simonovkon  он неплохой человек в жизни. Я ра...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Darina_Lo: Домааааа\\nЕхали на такси, пели ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  мыс на меня обиделась:(\\nя ей даже ничего не с...     -1\n",
       "1          аааааааааааааааааааа,не хочу на работу :(     -1\n",
       "2  У меня какой-то особенный вид ушей! :D, некото...      1\n",
       "3  @simonovkon  он неплохой человек в жизни. Я ра...     -1\n",
       "4  RT @Darina_Lo: Домааааа\\nЕхали на такси, пели ...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(txt, use_lemmatization = False):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "    letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "    analyzer = MorphAnalyzer()\n",
    "    result = ''\n",
    "    for letter in txt:\n",
    "        if letter in letters:\n",
    "            result += letter\n",
    "    if use_lemmatization:\n",
    "        temp = []\n",
    "        for word in result.split():\n",
    "            temp.append(analyzer.parse(word)[0].normal_form)\n",
    "        result = ' '.join(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_lemmatization = dataset['text'].apply(lambda x : clean(x, use_lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_without_lemmatization = dataset['text'].apply(lambda x : clean(x, use_lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_with_lemmatization.to_csv(\"data/data_with_lemmatization.csv\")\n",
    "dataset_without_lemmatization.to_csv(\"data/data_without_lemmatization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_lemmatization = pd.read_csv(\"data/data_with_lemmatization.csv\", header = None)\n",
    "dataset_without_lemmatization = pd.read_csv(\"data/data_without_lemmatization.csv\", header = None)\n",
    "dataset_with_lemmatization = dataset_with_lemmatization[[1,]]\n",
    "dataset_without_lemmatization = dataset_without_lemmatization[[1,]]\n",
    "dataset_with_lemmatization['label'] = dataset['label']\n",
    "dataset_without_lemmatization['label'] = dataset['label']\n",
    "dataset_with_lemmatization.columns, dataset_without_lemmatization.columns = ['text', 'label'], ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мыс на меня обиделась я ей даже ничего не сделала</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аааааааааааааааааааане хочу на работу</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>у меня какойто особенный вид ушей  некоторые в...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>он неплохой человек в жизни я работала в шоуб...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>домааааа ехали на такси пели песни отдыхали ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  мыс на меня обиделась я ей даже ничего не сделала     -1\n",
       "1             аааааааааааааааааааане хочу на работу      -1\n",
       "2  у меня какойто особенный вид ушей  некоторые в...      1\n",
       "3   он неплохой человек в жизни я работала в шоуб...     -1\n",
       "4    домааааа ехали на такси пели песни отдыхали ...      1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_without_lemmatization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мыс на меня обиделась я ей даже ничего не сделала</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аааааааааааааааааааане хочу на работу</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>у меня какойто особенный вид ушей  некоторые в...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>он неплохой человек в жизни я работала в шоуб...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>домааааа ехали на такси пели песни отдыхали ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  мыс на меня обиделась я ей даже ничего не сделала     -1\n",
       "1             аааааааааааааааааааане хочу на работу      -1\n",
       "2  у меня какойто особенный вид ушей  некоторые в...      1\n",
       "3   он неплохой человек в жизни я работала в шоуб...     -1\n",
       "4    домааааа ехали на такси пели песни отдыхали ...      1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_lemmatization = dataset_with_lemmatization.dropna()\n",
    "dataset_without_lemmatization = dataset_without_lemmatization.dropna()\n",
    "dataset_without_lemmatization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fd012f227f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(dataset_with_lemmatization['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Score of GS : 0.7583564784199621\n",
      "Parameters : {'alpha': 1e-06, 'loss': 'log', 'penalty': 'l2'}\n",
      "----------------------\n",
      "----------------------\n",
      "Score of GS : 0.7581549132268446\n",
      "Parameters : {'alpha': 1e-06, 'loss': 'log', 'penalty': 'l2'}\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "n_gram = (1, 3)\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", ngram_range=n_gram)\n",
    "datasets = [dataset_with_lemmatization, dataset_without_lemmatization]\n",
    "parameters = {\n",
    "        'loss': ('log', 'hinge'),\n",
    "        'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "        'alpha': [0.001, 0.0001, 0.00001, 0.000001]\n",
    "    }\n",
    "for data in datasets:\n",
    "    X = vectorizer.fit_transform(data['text'])\n",
    "    y = data['label']\n",
    "    cv = ShuffleSplit(len(y), n_iter = 5, test_size = 0.3, random_state = 0)\n",
    "    gs = GridSearchCV(SGDClassifier(), parameters, cv = cv)\n",
    "    gs.fit(X, y)\n",
    "    print('----------------------')\n",
    "    print('Score of GS : {}'.format(gs.best_score_))\n",
    "    print('Parameters : {}'.format(gs.best_params_))\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
